---
title:          "AgrEvader: Poisoning membership inference against Byzantine-robust federated learning"
date:           2023-04-30
selected:       true
pub:            "Proceedings of the ACM Web Conference 2023"
pub_date:       "2023"
abstract: >-
  The Poisoning Membership Inference Attack (PMIA) is a newly emerging privacy attack that poses a significant threat to federated learning (FL). An adversary conducts data poisoning (i.e., performing adversarial manipulations on training examples) to extract membership information by exploiting the changes in loss resulting from data poisoning. The PMIA significantly exacerbates the traditional poisoning attack that is primarily focused on model corruption. However, there has been a lack of a comprehensive systematic study that thoroughly investigates this topic. In this work, we conduct a benchmark evaluation to assess the performance of PMIA against the Byzantine-robust FL setting that is specifically designed to mitigate poisoning attacks. We find that all existing coordinate-wise averaging mechanisms fail to defend against the PMIA, while the detect-then-drop strategy was proven to be effective in most cases.
cover:          assets/images/covers/cover1.jpg
authors:
- Yanjun Zhang
- Guangdong Bai
- Mahawaga Arachchige Pathum Chamikara
- Mengyao Ma
- Liyue Shen
- Jingwei Wang
- Surya Nepal
- Minhui Xue
- Long Wang
- Joseph Liu
links:
  Paper: https://dl.acm.org/doi/abs/10.1145/3543507.3583542
---
